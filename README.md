# Iris Startup Lab
## Video to audio to speech to text AKA **Transcripton**



### Main Objective
The objective of this app is to create an AI Agent that helps to the company to translate several interviews and get the main kpis of this interviews since an "easy to use" interface.
#### Secondary Objectives
- Get the text from videos and audios 
- Get the main information of the trascripted text
- Use an LLM model in order to answer as a summary every question detected in the text.
- Allow to all users to download and get the charts in different images formats.

### Used tools
- [Whisper](https://github.com/openai/whisper) :speaker: 
    - A library that allow us to make the translation from audio to text.
- [Vader](https://hex.tech/templates/sentiment-analysis/vader-sentiment-analysis/) :space_invader:
    - A Python library that help us to made the sentiment analysis of the analyzed text.
- [Spacy](https://spacy.io/) :notes:
    - A library that help us to get the entities of the text like the verbs, the most important phrases and at the same time it help us to get the questions and get the names of the text in an easy way.
- [LLama3](https://ollama.com/library/llama3.3) :dromedary_camel:
    - An AI agent that could help us to get the summaries of the interviews
- [DeepSeek R1](https://ollama.com/library/deepseek-r1) :whale:
    - The next AI agent that is goint to replace LLama3 in order to improve the result.


Ahora un bender porque se ve bien

![](https://media.tenor.com/03-xmqploKcAAAAM/futurama-bender.gif)
